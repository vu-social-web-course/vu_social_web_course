{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "# The Social Web Assignment 4: Recommendation\n",
    "\n",
    "- Instructor: Davide Ceolin, Filip Ilievski, Zubaria Inayat\n",
    "- TAs: MÃ¡rton BodÃ³, Manav Neema, GÃ¶ktuÄŸ Genckaya and Chiara Michelutti.\n",
    "- Exercises for Hands-on session 4 \n",
    "*****************************************************\n",
    "\n",
    "In this notebook you will use the similarity measures to provide recommendations by comparing users and content based on expressed preferences (ratings). You will also explore textual similarity using a very popular natural language processing library, NLTK. Finally, you will explore recommendations on the Stack Overflow platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required packages:\n",
    "* feedparser, praw,  nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!pip install feedparser\n",
    "!pip install praw\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "> ðŸ’¡ **Info:** If the you get `command not found: pip` try with `pip3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!pip3 install feedparser\n",
    "!pip3 install praw\n",
    "!pip3 install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the snippets below, you can find:\n",
    "* creation of a small toy database in form of a dictionary of dictionaries;\n",
    "* issuing several similarity measures based on critics' preferences; and\n",
    "* use those values to obtain meaningful statistics pertaining a user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie preferences of movie critics\n",
    "As example data, let us define a python dictionary of movie critics and their ratings of a small set of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critics = {\n",
    "    'Lisa Rose': {\n",
    "        'Lady in the Water': 2.5,\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 3.0,\n",
    "        'Superman Returns': 3.5,\n",
    "        'You, Me and Dupree': 2.5,\n",
    "        'The Night Listener': 3.0,\n",
    "    },\n",
    "    'Gene Seymour': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 1.5,\n",
    "        'Superman Returns': 5.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'You, Me and Dupree': 3.5,\n",
    "    },\n",
    "    'Michael Phillips': {\n",
    "        'Lady in the Water': 2.5,\n",
    "        'Snakes on a Plane': 3.0,\n",
    "        'Superman Returns': 3.5,\n",
    "        'The Night Listener': 4.0,\n",
    "    },\n",
    "    'Claudia Puig': {\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 3.0,\n",
    "        'The Night Listener': 4.5,\n",
    "        'Superman Returns': 4.0,\n",
    "        'You, Me and Dupree': 2.5,\n",
    "    },\n",
    "    'Mick LaSalle': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 4.0,\n",
    "        'Just My Luck': 2.0,\n",
    "        'Superman Returns': 3.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'You, Me and Dupree': 2.0,\n",
    "    },\n",
    "    'Jack Matthews': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 4.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'Superman Returns': 5.0,\n",
    "        'You, Me and Dupree': 3.5,\n",
    "    },\n",
    "    'Toby': {'Snakes on a Plane': 4.5, \n",
    "             'You, Me and Dupree': 1.0,\n",
    "             'Superman Returns': 4.0},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercise 1: Finding Similar Users**\n",
    "\n",
    "In the code below, two different simililarity measures are used: Euclidean distance and the Pearson correlation. If you are not familiar with them, we recommend you look them up to deepen your understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidian distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the degree similarity between critics given their respective preferences, we can use the euclidian distance.\n",
    "Its formula for an N-dimensional space is is:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$d(\\mathbf{p}, \\mathbf{q}) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + \\cdots + (p_n - q_n)^2} = \\sqrt{\\sum_{i=1}^n (p_i - q_i)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we want a smaller distance to indicate a larger similarity, we will use 1/d(p,q) as our similarity value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def sim_distance(p1, p2, show_common_dims=False, prefs=critics):\n",
    "    '''\n",
    "    Returns a distance-based similarity score between two critics.\n",
    "    '''\n",
    "\n",
    "    # Get the list of shared_items\n",
    "    common_items = []\n",
    "    for movie in prefs[p1]:\n",
    "        if movie in prefs[p2]:\n",
    "            common_items.append(movie)\n",
    "    # If they have no ratings in common, return 0\n",
    "    if len(common_items) == 0:\n",
    "        return 0\n",
    "    if show_common_dims:\n",
    "        print(\"common dimensions between {} and {}: \".format(p1, p2) + str(len(common_items)))\n",
    "    # Add up the squares of all the differences\n",
    "    sum_of_squares = sum([pow(prefs[p1][movie] - prefs[p2][movie], 2) for movie in common_items])\n",
    "    \n",
    "    # return sqrt(sum_of_squares)\n",
    "    return 1 / sqrt(sum_of_squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this simple formula, you can calculate a similarity between two critics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distance between 'Lisa Rose' and 'Gene Seymour'\n",
    "sim_distance('Lisa Rose','Gene Seymour') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For yourself: Try this with other names so you can see who is closer or further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "Identify at least two potential bugs or errors in the `sim_distance` function code above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** (add your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different measure of similarity can be given by pearson correlation.\n",
    "Which follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$r_{xy} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^n (y_i - \\bar{y})^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the dividend represents a measure of covariance between dimensions, whereas the divisor is the product of the standard deviation of the scores given by each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_pearson(p1, p2, prefs=critics, verbose=False):\n",
    "    '''\n",
    "    Returns the Pearson correlation coefficient for p1 and p2.\n",
    "    '''\n",
    "\n",
    "    '''Step 1: Get the list of mutually rated items'''\n",
    "    common_items = []\n",
    "    dic = {}\n",
    "    for movie in prefs[p1]:\n",
    "        if movie in prefs[p2]:\n",
    "            common_items.append(movie)\n",
    "    # If they are no ratings in common, return 0\n",
    "    if len(common_items) == 0:\n",
    "        return 0\n",
    "    '''Step 2: Sum calculations'''\n",
    "    n_common_items = len(common_items)\n",
    "    sum1 = sum([prefs[p1][movie] for movie in common_items])\n",
    "    sum2 = sum([prefs[p2][movie] for movie in common_items])\n",
    "    # Sums of squares\n",
    "    sum1Sq = sum([pow(prefs[p1][movie], 2) for movie in common_items])\n",
    "    sum2Sq = sum([pow(prefs[p2][movie], 2) for movie in common_items])\n",
    "    # Sum of the products\n",
    "    pSum = sum([prefs[p1][movie] * prefs[p2][movie] for movie in common_items])\n",
    "    # Calculate r (Pearson score)\n",
    "    num = pSum - sum1 * sum2 / n_common_items\n",
    "    den = sqrt((sum1Sq - pow(sum1, 2) / n_common_items) * (sum2Sq - pow(sum2, 2) / n_common_items))\n",
    "    if den == 0:\n",
    "        return 0\n",
    "    r = num / den\n",
    "    if verbose:\n",
    "        print(\"common dimensions: %s\" % len(common_items))\n",
    "        print(\"Similarity Score for {} and {}: {}\".format(p1, p2, r))\n",
    "    return r\n",
    "\n",
    "for k in critics.keys():\n",
    "    sim_pearson('Michael Phillips', k, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the examples you used for the eucledian distance again, but now using the pearson correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_pearson('Lisa Rose','Gene Seymour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking critics on similarity\n",
    "The topMatches function below calculates all similarities of a given critic with his peers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topMatches(person, n=5, similarity=sim_pearson, prefs=critics):\n",
    "    '''\n",
    "    Returns the best matches for person from the prefs dictionary. \n",
    "    Number of results and similarity function are optional params.\n",
    "    '''\n",
    "    if similarity not in [sim_distance, sim_pearson]:\n",
    "        # NB: here we are comparing FUNCTION DEFINITION.\n",
    "        # We do that only in a jupyter notebook for the sake of simplicity.\n",
    "        raise ValueError(\"Callback functions should be: 'sim_pearson' or 'sim_distance'.\")\n",
    "        \n",
    "    scores = [(similarity(person, other, prefs=prefs), other) for other in prefs\n",
    "              if other != person]\n",
    "    scores.sort()\n",
    "    scores.reverse()\n",
    "    return scores[0:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can now get the 3 critics closest to Toby by calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topMatches('Toby',n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "*****************************************************\n",
    "### Task 1.A: Effect of similarity function used\n",
    "Call the topMatches function on a number of critics with both the default sim_pearson, but also with the sim_distance function. Would you have preference of one over the other? \n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for critic in critics.keys():\n",
    "    print(critic)\n",
    "    print(topMatches(critic,n=3))\n",
    "    print(topMatches(critic,n=3,similarity=sim_distance))\n",
    "    print(\"_____________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the differences that you found:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** (add the answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercise 2: Recommending Items**\n",
    "\n",
    "One way to recommend movies to a person would be to rate the movies she has not seen yet by using the scores of the others weighted by the similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecommendations(person, similarity=sim_pearson, prefs=critics):\n",
    "    '''\n",
    "    Gets recommendations for a person by using a weighted average\n",
    "    of every other user's rankings\n",
    "    '''\n",
    "    if similarity not in [sim_distance, sim_pearson]:\n",
    "        raise ValueError(\"Callback functions should be: 'sim_pearson' or 'sim_distance'.\")\n",
    "\n",
    "    totals = {}\n",
    "    simSums = {}\n",
    "    for other in prefs:\n",
    "    # Don't compare me to myself\n",
    "        if other == person:\n",
    "            continue\n",
    "        # print(person, other)\n",
    "        sim = similarity(person, other, prefs=prefs)\n",
    "    # Ignore scores of zero or lower\n",
    "        if sim <= 0: \n",
    "            continue\n",
    "        for item in prefs[other]:\n",
    "            # Only score movies I haven't seen yet\n",
    "            if item not in prefs[person] or prefs[person][item] == 0:\n",
    "                # Similarity * Score\n",
    "                    totals.setdefault(item, 0)\n",
    "                    # The final score is calculated by multiplying each item by the\n",
    "                    #   similarity and adding these products together\n",
    "                    totals[item] += prefs[other][item] * sim\n",
    "                    # Sum of similarities\n",
    "                    simSums.setdefault(item, 0)\n",
    "                    simSums[item] += sim\n",
    "    # Create the normalized list\n",
    "    rankings = [(total / simSums[item], item) for (item, total) in\n",
    "                totals.items()]\n",
    "    # Return the sorted list\n",
    "    rankings.sort()\n",
    "    rankings.reverse()\n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getRecommendations('Toby', similarity=sim_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getRecommendations('Toby')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output does not only consist of a movie title, but also a guess at what the user's rating for each movie would be.\n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.A: Explainable recommendations\n",
    "Users often want to know why an item was recommended. Modify the getRecommendations function so that it returns not just the predicted rating and movie title, but also the name of the \"closest\" critic (the user with the highest similarity score) who watched that movie. You can implement your solution in the function called `getRecommendations_plus`. (see defined bellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "def getRecommendations_plus():\n",
    "    '''\n",
    "    do not forget to add parameters to your function\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "getRecommendations_plus('Toby')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercise 3: Transformations** \n",
    "**You have been building recommendations based on similar users in Exercise 2, but you could of course also build recommendations based on similar items. In this exercise you will do this.** \n",
    "\n",
    "The function is essentially the same, but you need to transfer your data, from:\n",
    "\n",
    "<code>{'Lisa Rose': {'Lady in the Water': 2.5, 'Snakes on a Plane': 3.5},\n",
    "'Gene Seymour': {'Lady in the Water': 3.0, 'Snakes on a Plane': 3.5}}</code>\n",
    "\n",
    "to\n",
    "\n",
    "<code>{'Lady in the Water': {'Lisa Rose': 2.5,'Gene Seymour': 3.0},\n",
    "'Snakes on a Plane': {'Lisa Rose': 3.5,'Gene Seymour': 3.5}}</code>\n",
    "\n",
    "This is what the transformPrefs function does. \n",
    "\n",
    "You can now create a dictionary for movies with their scores assigned by different people by invoking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformPrefs(prefs=critics):\n",
    "    '''\n",
    "    Transform the recommendations into a mapping where persons are described\n",
    "    with interest scores for a given title e.g. {title: person} instead of\n",
    "    {person: title}.\n",
    "    '''\n",
    "    result = {}\n",
    "    for person in prefs:\n",
    "        for item in prefs[person]:\n",
    "            result.setdefault(item, {})\n",
    "            # Flip item and person\n",
    "            result[item][person] = prefs[person][item]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = transformPrefs()\n",
    "print(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And find similar items for a particular movie like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topMatches('Superman Returns', prefs=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or find people who may like a particular movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "getRecommendations('Just My Luck', prefs=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "*****************************************************\n",
    "### Task 3.A: Why does the example above work?\n",
    "Try to follow exactly what is going on in the last call. Notice that Michael and Jack did not rate 'Just my Luck'. How is their rating for it built up?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** (add your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercise 4: Sentence Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import natural language processing software we need later.\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download wordnet and punkt sentence tokenizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have some example sentences to compare later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = [\"I saw a really good movie last night.\",\n",
    "\"The movie is based on the director's life.\",\n",
    "\"The movie starts at ten.\",\n",
    "\"I took her to a movie.\",\n",
    "\"The movie stars Al Pacino.\",\n",
    "\"The movie opened last weekend.\",\n",
    "\"The movie lasted two hours.\",\n",
    "\"He directed several movies.\", \n",
    "\"We just shot another movie.\", \n",
    "\"The movie was set in New York.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the Jaccard Similarity of two sentences however, we first need to do some preprocessing in the form of Lemmatization and Tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(s1, s2):\n",
    "\n",
    "    #Import a Lemmatizer to get the root form of certain words\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    \n",
    "    #Tokenize both sentences to get each word separately\n",
    "    word_list1 = nltk.word_tokenize(s1)\n",
    "    word_list2 = nltk.word_tokenize(s2)\n",
    "    \n",
    "#     print(\"Tokenized sentence\", word_list1) #Uncomment to see an example of the tokenized sentence \n",
    "    \n",
    "    #Lemmatize both sentences\n",
    "    lemmatized_output1 = ' '.join([lemmatizer.lemmatize(w, 'v') for w in word_list1])\n",
    "    lemmatized_output2 = ' '.join([lemmatizer.lemmatize(w, 'v') for w in word_list2])\n",
    "    #print(lemmatized_output2)\n",
    "    return lemmatized_output1, lemmatized_output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "for x in range(len(movies)):\n",
    "    l1, l2 = compare(movies[0], movies[x])\n",
    "    print(\"Sentence 1:\", l1, '\\n', \"Sentence 2:\", l2, '\\n', \"Similarity Score:\", get_jaccard_sim(l1,l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "### Task 4A: In what scenario's could the Jaccard Similarity be more useful than the Euclidean distance and the Pearson Similarity metrics? Why is that? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** (add your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **Exercise 5: Building a Stack Overflow Recommender**\n",
    "\n",
    "In this exercise, you will build a simple recommender system using **Stack Overflow** data.  \n",
    "We assume that if a user answers questions associated with a specific **tag** (e.g., `python`), they likely have an interest or expertise in that technology.  \n",
    "\n",
    "By finding users who are active across similar tags, we can recommend **new technologies** to a target user.\n",
    "\n",
    "---\n",
    "####  **Prerequisites**\n",
    "\n",
    "You will need the **stackapi** library, which provides easy access to the Stack Exchange API without requiring OAuth for publicly available data.\n",
    "\n",
    "Install it using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stackapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ðŸ’¡ **Info:** If the you get `command not found: pip` try with `pip3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install stackapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task Description:**\n",
    "1) **Collection:** Find a list of active users from a specific technology tag (e.g., 'python').\n",
    "2) **Enrichment:** For every user found, download the other tags they are active in.\n",
    "3) **Similarity:** Calculate the Jaccard similarity between users based on their shared tags.\n",
    "4) **Recommendation:** Suggest new tags to a user based on what their \"neighbors\" are interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 1: Collection**. \n",
    "\n",
    "We need a \"seed\" group of users to analyze. To do this, we will ask the API for the top answerers for a specific tag.\n",
    "- API Endpoint: `tags/{tag}/top-answerers/period`\n",
    "- **Goal:** Create a dictionary where the keys are Usernames and the values will eventually hold their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stackapi import StackAPI\n",
    "\n",
    "# Initialize the API wrapper (we don't need an API key since it will be a small public requests)\n",
    "SITE = StackAPI('stackoverflow')\n",
    "\n",
    "def initializeUserDict(tag, count=10):\n",
    "    user_dict = {}\n",
    "    print(f\"Finding active users in tag: {tag}...\")\n",
    "    \n",
    "    # Fetch top answerers for the specific tag for the last month\n",
    "    users = SITE.fetch(f'tags/{tag}/top-answerers/month')\n",
    "    \n",
    "    # Slice the list to get only the number of users we want\n",
    "    top_users = users['items'][:count]\n",
    "    \n",
    "    for u in top_users:\n",
    "        try:\n",
    "            # We store the user_id (for looking them up later) \n",
    "            # and an empty dict for their future tags\n",
    "            display_name = u['user']['display_name']\n",
    "            user_id = u['user']['user_id']\n",
    "            \n",
    "            user_dict[display_name] = {'user_id': user_id, 'tags': {}} \n",
    "        except KeyError:\n",
    "            pass # Skip users with missing data\n",
    "            \n",
    "    return user_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell to collect your initial users.   \n",
    "Feel free to change `'python'` to `'java'`, `'javascript'`, or `'c++'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_users_raw = initializeUserDict('python', count=10)\n",
    "print(f\"Found {len(so_users_raw)} users.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see them we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in so_users_raw:\n",
    "    print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 2: Enrichment**\n",
    "Knowing a user likes 'python' isn't enough to make recommendations. We need to know what else they are active in. This creates a \"User-Item Profile.\"  \n",
    "\n",
    "In this step, we iterate through every user found in Part 1 and fetch their personal top tags.  \n",
    "- API Endpoint: `users/{ids}/tags`\n",
    "- **Note:** We add a small time delay (time.sleep) to be polite to the server and avoid getting rate-limited. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def fillItems(user_dict, count=20):\n",
    "    all_items = {}\n",
    "    \n",
    "    for username, data in user_dict.items():\n",
    "        user_id = data['user_id']\n",
    "        \n",
    "        try:\n",
    "            # Fetch the top tags for this specific user\n",
    "            tags = SITE.fetch(f'users/{user_id}/tags', order='desc', sort='popular')\n",
    "            \n",
    "            # Take the top 'count' tags\n",
    "            user_tags = tags['items'][:count]\n",
    "            \n",
    "            for t in user_tags:\n",
    "                tag_name = t['name']\n",
    "                \n",
    "                # We mark the score as 1.0 (indicating the user is active in this tag)\n",
    "                user_dict[username]['tags'][tag_name] = 1.0\n",
    "                all_items[tag_name] = 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching for {username}: {e}\")\n",
    "        \n",
    "        # delay\n",
    "        time.sleep(0.1) \n",
    "        \n",
    "    # Reformat dictionary to be {User: {Tag: Score, Tag: Score}}\n",
    "    final_dict = {name: data['tags'] for name, data in user_dict.items()}\n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this to download the tag data. This may take 10-20 seconds depending on your device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefs = fillItems(so_users_raw, count=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pprint` is a handy library to vislualize data in a more readable format. You can download it in the cell bellow: (for more info see [link](https://docs.python.org/3/library/pprint.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pprintpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's inspect one user to see what their data looks like\n",
    "first_user = list(prefs.keys())[0]\n",
    "pprint(f\"Data for {first_user}: {prefs[first_user]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 3: Similarity (Jaccard Index)**\n",
    "Now we have our data. To recommend tags, we first need to find which users are similar to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*kd2xV2qX3vvbOiC4XD0xbg.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the **Jaccard Similarity** coefficient.\n",
    "It measures the overlap between two sets:\n",
    "\n",
    "$$\n",
    "J(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}\n",
    "$$\n",
    "\n",
    "### Task 5.A: Implementing Jaccard Similarity Function \n",
    "\n",
    "If **User A** likes `{Python, Java}` and **User B** likes `{Python, C++}`:\n",
    "\n",
    "- **Intersection:** `{Python}` (size = 1)  \n",
    "- **Union:** `{Python, Java, C++}` (size = 3)  \n",
    "- **Similarity:** $\\frac{1}{3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(user1, user2, prefs):\n",
    "    # Extract the keys (tags) for both users into Sets\n",
    "    set1 = set(prefs[user1].keys())\n",
    "    set2 = set(prefs[user2].keys())\n",
    "\n",
    "    #TODO. IMPLEMENT JACCARD HERE \n",
    "    \n",
    "    # 1. Calculate the intersection (tags shared by both)\n",
    "    intersection = #TODO\n",
    "\n",
    "    # 2. Calculate the union (all unique tags across both)\n",
    "    union = #TODO\n",
    "\n",
    "    # 3. Handle division by zero (if union is empty, return 0)\n",
    "    #TODO\n",
    "\n",
    "    # 4. Return intersection divided by union\n",
    "    return #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function (Should return 0.5)\n",
    "test_prefs = {'A': {'python':1, 'java':1}, 'B': {'python':1, 'c++':1}}\n",
    "print(f\"Similarity score: {jaccard_similarity('A', 'B', test_prefs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 4: Recommendation**\n",
    "\n",
    "Finally, we generate recommendations.\n",
    "\n",
    "##### **The Logic**\n",
    "\n",
    "1. **Find users similar** to the target user.  \n",
    "2. **Identify tags** that similar users like, but the target user **has not used yet**.  \n",
    "3. **Weight each tag** by the similarity score:  \n",
    "   - A tag liked by a *very similar* user receives a **higher weight**.  \n",
    "   - A tag liked by a *less similar* user receives a **lower weight**.\n",
    "\n",
    "This produces a ranked list of recommended technologies for the user.\n",
    "\n",
    "### Task 5.B\n",
    "Using the logic above, complete the code below to test the recommendations generated for user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3653524782.py, line 11)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31msim = #TODO\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def getRecommendations(target_user, prefs):\n",
    "    totals = {}\n",
    "    simSums = {}\n",
    "\n",
    "    for other_user in prefs:\n",
    "        # Don't compare the user to themselves\n",
    "        if other_user == target_user: \n",
    "            continue\n",
    "\n",
    "        # Get similarity score using your function from Part 3\n",
    "        sim = #TODO\n",
    "\n",
    "        # Ignore users with zero or negative similarity\n",
    "        if sim <= 0: \n",
    "            continue\n",
    "\n",
    "        for tag in prefs[other_user]:\n",
    "            # Only score tags the target_user DOES NOT already have\n",
    "            if tag not in prefs[target_user]:\n",
    "                \n",
    "                # TODO CALCULATE SCORES\n",
    "                \n",
    "                # 1. Weighted Score: Similarity * Item Score (The item score is 1.0)\n",
    "                totals.setdefault(tag, 0)\n",
    "                totals[tag] += #TODO\n",
    "                \n",
    "                # 2. Keep track of sum of similarities for normalization\n",
    "                simSums.setdefault(tag, 0)\n",
    "                #TODO\n",
    "\n",
    "    # Create the normalized list: Total Score / Sum of Similarities\n",
    "    rankings = [(total / simSums[tag], tag) for tag, total in totals.items()]\n",
    "\n",
    "    # Sort descending (best recommendations first)\n",
    "    #TODO.\n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test your code in the cell bellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Pick a random user\n",
    "target = random.choice(list(prefs.keys()))\n",
    "print(f\"Recommendations for {target}:\")\n",
    "\n",
    "# Get top 5 recommendations\n",
    "recs = getRecommendations(target, prefs)\n",
    "for score, tag in recs[:5]:\n",
    "    print(f\"{tag} (Confidence: {score:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
